---
sidebar_position: 3
sidebar_label: Quick start with Rust
title: Embeddings models for Rust
description: This section contains information about different embedding models you can use with SurrealDB.
---

import Tabs from "@components/Tabs/Tabs.astro";
import TabItem from "@components/Tabs/TabItem.astro";

# ðŸ¦€ Embeddings

SurrealDB offers comprehensive support for vector embeddings, enabling powerful semantic search and machine learning capabilities across your data. Through integrations with leading embedding providers, you can easily store, index and query high-dimensional vectors alongside your regular data.

<Tabs>
<TabItem label="Mistral">

## Mistral

```rust
use mistralai_client::v1::{client::Client, constants::EmbedModel};

static KEY = std::env::var("MISTRAL_API_KEY").unwrap();

// ...

let client = Client::new(Some(KEY.to_string()), None, None, None)?;
let input = vec!["Joram is the main character in the Darksword Trilogy.".to_string()];

let result = client.embeddings_async(MODEL, input, None).await?;
println!("{:?}", result);
```

Find a full example in [Semantic search in Rust with SurrealDB and Mistral AI](/blog/semantic-search-in-rust-with-surrealdb-and-mistral-ai#generate-mistral-ai-embeddings).

</TabItem>
<TabItem label="Ollama">

## Ollama

```rust
use ollama_rs::{Ollama, generation::embeddings::GenerateEmbeddingsRequest};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let ollama = Ollama::default();

    let model = "all-minilm:22m".to_string()
    let prompt = "this is your input text".to_string();

    let request = GenerateEmbeddingsRequest::new(model, prompt);
    let response = ollama.generate_embeddings(request).await?;

    println!("Generated embeddings (first 5): {:?}", &response.embeddings[..5]);
    println!("Embedding vector length: {}", response.embeddings.len());

    Ok(())
}
```

</TabItem>
<TabItem label="SentenceTransformer">

## SentenceTransformer

```rust
use rust_bert::sentence_embeddings::{
    SentenceEmbeddingsBuilder, SentenceEmbeddingsModelType,
};

fn main() -> anyhow::Result<()> {
    // Set up the model builder, specifying the model type
    let model = SentenceEmbeddingsBuilder::remote(
        SentenceEmbeddingsModelType::AllMiniLmL6V2
    ).create_model()?;

    // Define the sentences to embed
    let sentences = [
        "this is your text",
        "you can encode more than one in batch"
    ];

    // Generate the embeddings
    let embeddings = model.encode(&sentences)?;

    // Print the results
    for (i, embedding) in embeddings.iter().enumerate() {
        // Truncate for display purposes
        let truncated_embedding: Vec<_> = embedding.iter().take(5).cloned().collect();

        println!("\nSentence: '{}'", sentences[i]);
        println!("Embedding (first 5 values): {:?}", truncated_embedding);
        println!("Embedding dimensions: {}", embedding.len());
    }

    Ok(())
}
```

</TabItem>
</Tabs>
